{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f279d7-70a3-4ae5-a3d4-23e2b1323ddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Download the gps data (Note: Change the \"url\" for your choice of navigation satellite)\n",
    "import requests\n",
    "\n",
    "def download_gps_tle(save_path=\"gps-ops.tle\"):\n",
    "    \"\"\"\n",
    "    Downloads the GPS Operational TLE data from CelesTrak\n",
    "    and saves it to the specified file path.\n",
    "    \"\"\"\n",
    "    url = \"https://celestrak.org/NORAD/elements/gp.php\"\n",
    "    params = {\n",
    "        \"GROUP\": \"gps-ops\",\n",
    "        \"FORMAT\": \"tle\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # Raises an error for bad responses (4xx, 5xx)\n",
    "    \n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(response.text)\n",
    "    \n",
    "    print(f\"GPS Operational TLE data saved to '{save_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_gps_tle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72ec039-0bd9-435f-9a13-8fd6b12a5379",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Scrubbing gps data\n",
    "%python\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number, floor, col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Read the TLE file as a DataFrame\n",
    "tle_lines = spark.read.text(\n",
    "    \"/Volumes/workspace/default/spacedata/gps-ops.tle\"\n",
    ").withColumnRenamed(\"value\", \"line\")\n",
    "\n",
    "# Add a unique id to each row\n",
    "tle_lines = tle_lines.withColumn(\n",
    "    \"unique_id\", monotonically_increasing_id()\n",
    ")\n",
    "\n",
    "# Add a row number to group every 3 lines\n",
    "window = Window.orderBy(\"unique_id\")\n",
    "tle_with_rownum = tle_lines.withColumn(\n",
    "    \"row_num\", row_number().over(window)\n",
    ")\n",
    "\n",
    "# Assign a group id for each TLE triplet\n",
    "tle_with_group = tle_with_rownum.withColumn(\n",
    "    \"group_id\", floor((col(\"row_num\") - 1) / 3)\n",
    ")\n",
    "\n",
    "# Pivot the lines into columns: name, line1, line2\n",
    "tle_with_group = tle_with_group.withColumn(\n",
    "    \"line_type\", ((col(\"row_num\") - 1) % 3)\n",
    ")\n",
    "\n",
    "tle_pivoted = tle_with_group.groupBy(\"group_id\").pivot(\n",
    "    \"line_type\", [0, 1, 2]\n",
    ").agg({\"line\": \"first\"})\n",
    "\n",
    "# Rename columns for clarity\n",
    "tle_df = tle_pivoted.select(\n",
    "    col(\"0\").alias(\"name\"),\n",
    "    col(\"1\").alias(\"line1\"),\n",
    "    col(\"2\").alias(\"line2\")\n",
    ")\n",
    "\n",
    "display(tle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5dd659-0354-42cb-ac9a-d1c45bfc9196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Writing the data into a csv\n",
    "%python\n",
    "# Save the parsed TLE DataFrame as a CSV for use in Pandas/sgp4\n",
    "tle_df.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    \"/Volumes/workspace/default/spacedata/gps-ops.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce8f8b3c-1f8b-490f-98ff-e3fdec0d507e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Writing the data into a delta table\n",
    "%python\n",
    "tle_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.gps_ops_tle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc44f2b-334e-472e-9f7f-6c110feee482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "%pip install sgp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b14da353-c306-44b1-a929-d4bd6a697acd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import pandas as pd\n",
    "from sgp4.api import Satrec, jday\n",
    "\n",
    "df = spark.read.format(\"delta\").table(\"default.gps_ops_tle\")\n",
    "pdf = df.toPandas()\n",
    "\n",
    "sat = Satrec.twoline2rv(\n",
    "    pdf.loc[0, \"line1\"],\n",
    "    pdf.loc[0, \"line2\"]\n",
    ")\n",
    "\n",
    "jd, fr = jday(2025, 8, 19, 0, 0, 0)\n",
    "e, r, v = sat.sgp4(jd, fr)\n",
    "\n",
    "print(\"Error code:\", e)\n",
    "print(\"Position (km):\", r)\n",
    "print(\"Velocity (km/s):\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "655a23b1-42ad-41a3-aaa4-375b947e9eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Parsing the gps data(TLE lines)\n",
    "from pyspark.sql.functions import substring, trim\n",
    "\n",
    "df = spark.read.format(\"delta\").table(\"default.gps_ops_tle\")\n",
    "\n",
    "parsed_df = df.select(\n",
    "    \"name\",\n",
    "    \"line1\",\n",
    "    \"line2\",\n",
    "    # Example: NORAD Catalog Number (columns 3-7 in line1)\n",
    "    trim(substring(\"line1\", 3, 5)).alias(\"norad_cat_id\"),\n",
    "    # Example: Inclination (columns 9-16 in line2)\n",
    "    trim(substring(\"line2\", 9, 8)).alias(\"inclination_deg\"),\n",
    "    # Example: RA of Ascending Node (columns 18-25 in line2)\n",
    "    trim(substring(\"line2\", 18, 8)).alias(\"raan_deg\"),\n",
    "    # Example: Eccentricity (columns 27-33 in line2)\n",
    "    trim(substring(\"line2\", 27, 7)).alias(\"eccentricity\"),\n",
    "    # Example: Argument of Perigee (columns 35-42 in line2)\n",
    "    trim(substring(\"line2\", 35, 8)).alias(\"arg_perigee_deg\"),\n",
    "    # Example: Mean Anomaly (columns 44-51 in line2)\n",
    "    trim(substring(\"line2\", 44, 8)).alias(\"mean_anomaly_deg\"),\n",
    "    # Example: Mean Motion (columns 53-63 in line2)\n",
    "    trim(substring(\"line2\", 53, 11)).alias(\"mean_motion\")\n",
    ")\n",
    "\n",
    "parsed_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.gps_ops_tle_parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88df4e7b-38ac-4dbf-9429-5cec6ee271e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34dad28d-b7ec-4811-a4e2-a4b083aba953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gps = spark.read.table(\"workspace.default.gps_ops_tle_parsed\").alias(\"gps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "441ecff8-161f-44a8-9dca-b1ea8d5b4125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Joining the TLE data with the GPS data to filter out the GPS satellites\n",
    "df_orbital = spark.read.table(\"workspace.default.parsed_orbital_elements\").alias(\"orb\")\n",
    "df_gps = spark.read.table(\"workspace.default.gps_ops_tle_parsed\").alias(\"gps\")\n",
    "\n",
    "df_navigation = df_orbital.join(\n",
    "    df_gps,\n",
    "    df_orbital[\"NORAD_CAT_ID\"] == df_gps[\"norad_cat_id\"],\n",
    "    \"left\"\n",
    ")\n",
    "display(df_navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89f554a-1d79-41a6-8c13-1c374c8cf086",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1756507273514}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_orbital = spark.read.table(\"workspace.default.parsed_orbital_elements\").alias(\"orb\")\n",
    "df_gps = spark.read.table(\"workspace.default.gps_ops_tle_parsed\").alias(\"gps\")\n",
    "\n",
    "df_flagged = df_orbital.join(\n",
    "    df_gps,\n",
    "    df_orbital[\"NORAD_CAT_ID\"] == df_gps[\"norad_cat_id\"],\n",
    "    \"left\"\n",
    ").withColumn(\n",
    "    \"is_gps_satellite\",\n",
    "    when(df_gps[\"norad_cat_id\"].isNotNull(), True).otherwise(False)\n",
    ")\n",
    "\n",
    "display(df_flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acae3763-7921-46bd-8995-f236411147cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  `column_name`,\n",
    "  `data_type`,\n",
    "  `comment`\n",
    "FROM \n",
    "  `information_schema`.`columns`\n",
    "WHERE \n",
    "  `table_catalog` = 'workspace' \n",
    "  AND `table_schema` = 'default' \n",
    "  AND `table_name` = 'parsed_orbital_elements_flagged';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a73111-b9f9-4cbb-984e-8bc47e5716e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop the 'mean_motion' and 'eccentricity_gps' columns\n",
    "df_flagged = df_flagged.drop(\"mean_motion\", \"eccentricity_gps\",\"norad_cat_id\")\n",
    "\n",
    "# Save the DataFrame as a Delta table\n",
    "df_flagged.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.parsed_orbital_elements_flagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "216507c7-7d00-48cb-8a51-56353d4f7a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# Read the Delta table\n",
    "df_gps = spark.read.table(\"workspace.default.gps_ops_tle_parsed\")\n",
    "# Writing the data into a CSV\n",
    "\n",
    "# Save the parsed TLE DataFrame as a CSV for use in Pandas/sgp4\n",
    "df_gps.write.option(\"header\", True).mode(\"overwrite\").csv(\n",
    "    \"/Volumes/workspace/default/spacedata/gps-ops\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f54efd7-2595-4ad2-b200-fb1bf1b10cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_gps  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81294d28-fef2-4fe4-a72a-323ea3422afa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sgp4.api import Satrec, jday\n",
    "\n",
    "# Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load from Delta\n",
    "df = spark.read.table(\"workspace.default.parsed_orbital_elements_flagged\")\n",
    "\n",
    "# Convert to Pandas for propagation (SGP4 works easier with Python objects)\n",
    "sat_df = df.toPandas()\n",
    "\n",
    "# Split NAVSTAR vs others\n",
    "navstar_df = sat_df[sat_df[\"is_gps_satellite\"] == True].copy()\n",
    "others_df  = sat_df[sat_df[\"is_gps_satellite\"] == False].copy()\n",
    "\n",
    "# Target epoch (Sept 10, 2025)\n",
    "year, month, day, hour, minute, second = 2025, 9, 10, 0, 0, 0\n",
    "jd, fr = jday(year, month, day, hour, minute, second)\n",
    "\n",
    "def propagate(line1, line2):\n",
    "    sat = Satrec.twoline2rv(line1, line2)\n",
    "    e, r, v = sat.sgp4(jd, fr)\n",
    "    if e == 0:\n",
    "        return np.array(r)  # [X, Y, Z]\n",
    "    return None\n",
    "\n",
    "# Propagate NAVSTAR sats\n",
    "navstar_positions = []\n",
    "for _, row in navstar_df.iterrows():\n",
    "    pos = propagate(row[\"TLE_LINE1\"], row[\"TLE_LINE2\"])\n",
    "    if pos is not None:\n",
    "        navstar_positions.append({\n",
    "            \"Satellite\": row[\"OBJECT_NAME\"],\n",
    "            \"Object_ID\": row[\"OBJECT_ID\"],\n",
    "            \"Object_Type\": row[\"OBJECT_TYPE\"],\n",
    "            \"ORBIT_CLASS\": row[\"ORBIT_CLASS\"],\n",
    "            \"X\": pos[0],\n",
    "            \"Y\": pos[1],\n",
    "            \"Z\": pos[2]\n",
    "        })\n",
    "navstar_positions = pd.DataFrame(navstar_positions)\n",
    "\n",
    "# Propagate other sats\n",
    "other_positions = []\n",
    "for _, row in others_df.iterrows():\n",
    "    pos = propagate(row[\"TLE_LINE1\"], row[\"TLE_LINE2\"])\n",
    "    if pos is not None:\n",
    "        other_positions.append({\n",
    "            \"Satellite\": row[\"OBJECT_NAME\"],\n",
    "            \"Object_ID\": row[\"OBJECT_ID\"],\n",
    "            \"Object_Type\": row[\"OBJECT_TYPE\"],\n",
    "            \"ORBIT_CLASS\": row[\"ORBIT_CLASS\"],\n",
    "            \"X\": pos[0],\n",
    "            \"Y\": pos[1],\n",
    "            \"Z\": pos[2]\n",
    "        })\n",
    "other_positions = pd.DataFrame(other_positions)\n",
    "\n",
    "# Nearest neighbors calculation\n",
    "nearest_results = []\n",
    "for _, nav in navstar_positions.iterrows():\n",
    "    nav_pos = np.array([nav[\"X\"], nav[\"Y\"], nav[\"Z\"]])\n",
    "\n",
    "    other_positions[\"Distance_km\"] = np.linalg.norm(\n",
    "        other_positions[[\"X\",\"Y\",\"Z\"]].values - nav_pos, axis=1\n",
    "    )\n",
    "\n",
    "    nearest = other_positions.nsmallest(5, \"Distance_km\")\n",
    "    for _, near in nearest.iterrows():\n",
    "        nearest_results.append({\n",
    "            \"NAVSTAR\": nav[\"Satellite\"],\n",
    "            \"Nearest_Sat\": near[\"Satellite\"],\n",
    "            \"Object_ID\": near[\"Object_ID\"],\n",
    "            \"Distance_km\": near[\"Distance_km\"],\n",
    "            \"Object_Type\": near[\"Object_Type\"],\n",
    "            \"ORBIT_CLASS\": near[\"ORBIT_CLASS\"],\n",
    "        })\n",
    "\n",
    "nearest_df = pd.DataFrame(nearest_results)\n",
    "\n",
    "# Save back to Delta for reuse\n",
    "nearest_spark_df = spark.createDataFrame(nearest_df)\n",
    "nearest_spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.navstar_nearest_neighbors\")\n",
    "display(nearest_spark_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "829198eb-ce78-4cda-98e8-e24c6a465b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "navstar_df = sat_df[sat_df[\"is_gps_satellite\"] == True].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd0950b-709a-4c7f-8e74-6ae99b41a15a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(navstar_df )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4951490041253113,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Calestrak_data_for_navigation_sat",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
