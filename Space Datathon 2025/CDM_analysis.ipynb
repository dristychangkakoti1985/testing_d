{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a566094b-89d1-47d3-8d93-250a401d3a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "%pip install sgp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c97813fc-0276-432b-8d3a-a770dd1a8639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cluster_cdm_by_orbit.py\n",
    "# pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from math import pi\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "# INPUT_FILE = \"/mnt/data/CDM_data_profile.xlsx\"\n",
    "# SHEET_NAME = \"Sheet1\"\n",
    "N_CLUSTERS = 6\n",
    "RANDOM_SEED = 42\n",
    "ALT_BIN_SIZE = 50  # for optional altitude binning visualization\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Helpers to detect columns\n",
    "# --------------------------\n",
    "def pick(col_names, choices):\n",
    "    for c in choices:\n",
    "        if c in col_names:\n",
    "            return c\n",
    "        for col in col_names:\n",
    "            if col.lower() == c.lower():\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "# --------------------------\n",
    "# Load data (CDM joined with TLE rows)\n",
    "# --------------------------\n",
    "# Read directly from Delta\n",
    "df_spark = spark.read.table(\"workspace.default.cdms_data_profile_v1\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to Pandas for sklearn/seaborn analysis\n",
    "df = df_spark.toPandas()\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "# detect columns we need (flexible)\n",
    "col_norad = pick(cols, [\"NORAD_CAT_ID_p\", \"NORAD_CAT_ID\", \"NORAD\", \"NORAD_CAT_ID_A\", \"NORAD_CAT_ID_B\", \"OBJECT_ID\"])\n",
    "col_alt   = pick(cols, [\"ALTITUDE_KM\", \"altitude_km\", \"altitude\", \"ALTITUDE\", \"alt_km\", \"altitude_km\"])\n",
    "col_inc   = pick(cols, [\"INCLINATION\", \"inclination\", \"inclination_deg\", \"inclination_p\", \"i\"])\n",
    "col_mm    = pick(cols, [\"MEAN_MOTION\", \"mean_motion\", \"MEAN_MOTION_p\", \"mean_motion_p\"])\n",
    "col_sat1  = pick(cols, [\"SAT_1_ID\", \"SAT1\", \"SAT_1\", \"OBJECT1_ID\", \"OBJECT_A\", \"NORAD_A\", \"NORAD_CAT_ID_A\"])\n",
    "col_sat2  = pick(cols, [\"SAT_2_ID\", \"SAT2\", \"SAT_2\", \"OBJECT2_ID\", \"OBJECT_B\", \"NORAD_B\", \"NORAD_CAT_ID_B\"])\n",
    "col_ecc   = pick(cols, [\"ECCENTRICITY\", \"eccentricity\", \"eccentricity_p\", \"e\"])\n",
    "col_tle1  = pick(cols, [\"TLE_LINE1\", \"line1\", \"TLE1\", \"line_1\"])\n",
    "col_tle2  = pick(cols, [\"TLE_LINE2\", \"line2\", \"TLE2\", \"line_2\"])\n",
    "\n",
    "print(\"Detected columns:\")\n",
    "print(\"  NORAD:\", col_norad)\n",
    "print(\"  ALT:\", col_alt)\n",
    "print(\"  INC:\", col_inc)\n",
    "print(\"  MEAN_MOTION:\", col_mm)\n",
    "print(\"  SAT1:\", col_sat1)\n",
    "print(\"  SAT2:\", col_sat2)\n",
    "print(\"  ECC:\", col_ecc)\n",
    "print(\"  TLE1/TLE2:\", col_tle1, col_tle2)\n",
    "\n",
    "# --------------------------\n",
    "# Build a per-object table (one row per NORAD)\n",
    "# --------------------------\n",
    "# Some rows in df represent conjunction events between two NORADs.\n",
    "# We collect unique NORAD entries and keep the first available orbital parameters.\n",
    "# We'll search both SAT1 and SAT2 columns and also a single NORAD column if present.\n",
    "\n",
    "# gather candidate NORAD ids\n",
    "norad_ids = set()\n",
    "if col_sat1 and col_sat2:\n",
    "    norad_ids.update(df[col_sat1].dropna().astype(str).unique().tolist())\n",
    "    norad_ids.update(df[col_sat2].dropna().astype(str).unique().tolist())\n",
    "elif col_norad:\n",
    "    norad_ids.update(df[col_norad].dropna().astype(str).unique().tolist())\n",
    "else:\n",
    "    # fallback: try OBJECT_ID column or index\n",
    "    if \"OBJECT_ID\" in cols:\n",
    "        norad_ids.update(df[\"OBJECT_ID\"].dropna().astype(str).unique().tolist())\n",
    "\n",
    "norad_ids = sorted([x for x in norad_ids if str(x).strip() != \"nan\"])\n",
    "print(f\"Found {len(norad_ids)} unique NORAD ids in CDM/TLE file sample.\")\n",
    "\n",
    "# For each NORAD, try to get altitude and inclination from any row where it appears\n",
    "objects = []\n",
    "for norad in norad_ids:\n",
    "    # find rows where this norad appears\n",
    "    mask = False\n",
    "    if col_sat1 and col_sat2:\n",
    "        mask = (df[col_sat1].astype(str) == str(norad)) | (df[col_sat2].astype(str) == str(norad))\n",
    "    elif col_norad:\n",
    "        mask = (df[col_norad].astype(str) == str(norad))\n",
    "    else:\n",
    "        mask = (df.get(\"OBJECT_ID\", pd.Series(dtype=str)).astype(str) == str(norad))\n",
    "    rows = df[mask]\n",
    "    # pick first row that has orbital info\n",
    "    alt = np.nan; inc = np.nan; ecc = np.nan; mm = np.nan; tle1 = None; tle2 = None\n",
    "    for _, r in rows.iterrows():\n",
    "        if pd.isna(alt) and col_alt and pd.notna(r.get(col_alt)):\n",
    "            try:\n",
    "                alt = float(r[col_alt])\n",
    "            except:\n",
    "                alt = np.nan\n",
    "        if pd.isna(inc) and col_inc and pd.notna(r.get(col_inc)):\n",
    "            try:\n",
    "                inc = float(r[col_inc])\n",
    "            except:\n",
    "                inc = np.nan\n",
    "        if pd.isna(ecc) and col_ecc and pd.notna(r.get(col_ecc)):\n",
    "            try:\n",
    "                ecc = float(r[col_ecc])\n",
    "            except:\n",
    "                ecc = np.nan\n",
    "        if pd.isna(mm) and col_mm and pd.notna(r.get(col_mm)):\n",
    "            try:\n",
    "                mm = float(r[col_mm])\n",
    "            except:\n",
    "                mm = np.nan\n",
    "        if (not tle1) and col_tle1 and pd.notna(r.get(col_tle1)):\n",
    "            tle1 = r[col_tle1]\n",
    "        if (not tle2) and col_tle2 and pd.notna(r.get(col_tle2)):\n",
    "            tle2 = r[col_tle2]\n",
    "        # break when we have alt and inc\n",
    "        if (not np.isnan(alt)) and (not np.isnan(inc)):\n",
    "            break\n",
    "\n",
    "    # if altitude missing but mean motion present, compute altitude\n",
    "    if np.isnan(alt) and (not np.isnan(mm)):\n",
    "        # mean motion in rev/day -> period and semi-major axis -> altitude\n",
    "        n = mm\n",
    "        # avoid invalid\n",
    "        try:\n",
    "            n_rad_s = n * 2 * pi / 86400.0\n",
    "            a = (398600.4418 / (n_rad_s**2)) ** (1.0/3.0)\n",
    "            alt = a - 6378.137\n",
    "        except:\n",
    "            alt = np.nan\n",
    "\n",
    "    objects.append({\n",
    "        \"NORAD\": str(norad),\n",
    "        \"altitude_km\": alt,\n",
    "        \"inclination_deg\": inc,\n",
    "        \"eccentricity\": ecc,\n",
    "        \"mean_motion\": mm,\n",
    "        \"TLE_LINE1\": tle1,\n",
    "        \"TLE_LINE2\": tle2\n",
    "    })\n",
    "\n",
    "objects_df = pd.DataFrame(objects)\n",
    "\n",
    "# drop rows missing altitude or inclination\n",
    "objects_df_clean = objects_df.dropna(subset=[\"altitude_km\", \"inclination_deg\"]).reset_index(drop=True)\n",
    "print(\"Objects with both altitude & inclination:\", len(objects_df_clean))\n",
    "\n",
    "# --------------------------\n",
    "# Compute CDM frequency per NORAD (how many CDM events mention this object)\n",
    "# --------------------------\n",
    "# If SAT1/SAT2 columns available, count occurrences\n",
    "if col_sat1 and col_sat2:\n",
    "    c1 = df[col_sat1].astype(str).value_counts()\n",
    "    c2 = df[col_sat2].astype(str).value_counts()\n",
    "    counts = c1.add(c2, fill_value=0)\n",
    "elif col_norad:\n",
    "    counts = df[col_norad].astype(str).value_counts()\n",
    "else:\n",
    "    counts = pd.Series(0, index=objects_df_clean[\"NORAD\"].astype(str))\n",
    "\n",
    "# join counts into objects_df_clean\n",
    "objects_df_clean[\"cdm_event_count\"] = objects_df_clean[\"NORAD\"].map(lambda x: int(counts.get(str(x), 0)))\n",
    "\n",
    "# --------------------------\n",
    "# Feature matrix and clustering\n",
    "# --------------------------\n",
    "X = objects_df_clean[[\"altitude_km\", \"inclination_deg\"]].to_numpy()\n",
    "# scale features to similar ranges (simple standardization)\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0) + 1e-9\n",
    "Xz = (X - X_mean) / X_std\n",
    "\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=RANDOM_SEED)\n",
    "labels = kmeans.fit_predict(Xz)\n",
    "objects_df_clean[\"cluster\"] = labels\n",
    "centers = (kmeans.cluster_centers_ * X_std) + X_mean  # back to original scale\n",
    "\n",
    "# compute cluster-level stats\n",
    "cluster_stats = objects_df_clean.groupby(\"cluster\").agg(\n",
    "    n_objects = (\"NORAD\", \"count\"),\n",
    "    total_cdm_events = (\"cdm_event_count\", \"sum\"),\n",
    "    mean_alt = (\"altitude_km\", \"mean\"),\n",
    "    mean_inc = (\"inclination_deg\", \"mean\")\n",
    ").reset_index().sort_values(\"total_cdm_events\", ascending=False)\n",
    "\n",
    "print(\"\\nCluster summary (sorted by total CDM events):\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# --------------------------\n",
    "# Plots\n",
    "# --------------------------\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 1) Scatter: altitude vs inclination colored by cluster, size ~ cdm_event_count\n",
    "plt.figure(figsize=(12,7))\n",
    "palette = sns.color_palette(\"tab10\", N_CLUSTERS)\n",
    "for c in range(N_CLUSTERS):\n",
    "    sub = objects_df_clean[objects_df_clean[\"cluster\"]==c]\n",
    "    plt.scatter(sub[\"altitude_km\"], sub[\"inclination_deg\"],\n",
    "                s = 20 + (sub[\"cdm_event_count\"]*2),  # size scaled by events\n",
    "                c = np.array([palette[c]]), label=f\"cluster {c} (n={len(sub)})\", alpha=0.8, edgecolors=\"k\")\n",
    "# cluster centers\n",
    "for idx, (a, i) in enumerate(centers[:, :2]):\n",
    "    plt.scatter(a, i, marker=\"X\", s=150, c=\"black\")\n",
    "    plt.text(a, i, f\"C{idx}\", fontsize=9, fontweight=\"bold\", ha=\"center\", va=\"center\", color=\"white\")\n",
    "plt.xlabel(\"Altitude (km)\")\n",
    "plt.ylabel(\"Inclination (deg)\")\n",
    "plt.title(\"Clusters by Altitude & Inclination (size ~ CDM event count)\")\n",
    "plt.legend(bbox_to_anchor=(1.05,1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"clusters_alt_inc_scatter.png\")\n",
    "plt.show()\n",
    "\n",
    "# 2) Bar: total CDM events per cluster\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=\"cluster\", y=\"total_cdm_events\", data=cluster_stats, palette=\"tab10\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Total CDM events (cluster)\")\n",
    "plt.title(\"Total CDM events per cluster\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cluster_total_cdm_events.png\")\n",
    "plt.show()\n",
    "\n",
    "# 3) Table: top NORADs by CDM count within top clusters\n",
    "top_clusters = cluster_stats.head(3)[\"cluster\"].tolist()\n",
    "top_list = objects_df_clean[objects_df_clean[\"cluster\"].isin(top_clusters)].sort_values(\"cdm_event_count\", ascending=False).head(50)\n",
    "top_list.to_csv(\"top_objects_by_cluster_and_cdm.csv\", index=False)\n",
    "print(\"\\nSaved top objects CSV: top_objects_by_cluster_and_cdm.csv\")\n",
    "\n",
    "# 4) Heatmap: cluster vs altitude band counts (optional)\n",
    "objects_df_clean[\"alt_band\"] = pd.cut(objects_df_clean[\"altitude_km\"], bins=np.arange(0, np.max(objects_df_clean[\"altitude_km\"])+ALT_BIN_SIZE, ALT_BIN_SIZE))\n",
    "heat = objects_df_clean.pivot_table(index=\"alt_band\", columns=\"cluster\", values=\"NORAD\", aggfunc=\"count\", fill_value=0)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(heat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Object counts per altitude band vs cluster\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heat_altband_cluster.png\")\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Save outputs\n",
    "# --------------------------\n",
    "objects_df_clean.to_csv(\"objects_clustered_with_cdm_counts.csv\", index=False)\n",
    "cluster_stats.to_csv(\"cluster_stats_summary.csv\", index=False)\n",
    "print(\"\\nSaved outputs: objects_clustered_with_cdm_counts.csv, cluster_stats_summary.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CDM_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
